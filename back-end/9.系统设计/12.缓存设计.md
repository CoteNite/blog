# 缓存设计

当服务器的流量过大时，我们往往会使用缓存的方式来减缓数据库压力，一般会使用Redis（分布式缓存），而Redis也有自己的问题（三大问题），因此会又会采取本地缓存（单机缓存）与其互补，让本地缓存预先再抗住一部分的流量

在一般的系统设计中，我们会预先对流量进行一系列的处理（OpenRestry，Sentinel，Guava RateLimter），之后才会到达我们的系统，这时我们一般就会认为这一次访问是正常的访问了，但在高并发的场景下（比如秒杀场景），我们仍然要想法设法的来避免大量流量导致的服务异常

## 整体设计

一般会从读写两个角度来看

### 读 

一般是层层递进，先去本地缓存去读，读不到进入分布式缓存，最后再去数据库读，若在某一层读到，则立即返回，同时异步的向前面的层去更新缓存

### 写

写的顺序一般是和读的顺序相反，用户持久化一个数据到数据库后，我们就立刻返回给用户一个结果，然后异步的去将持久化的数据更新到缓存中


